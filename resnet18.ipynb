{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5b2ae9-7db2-4834-9736-e6805655316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "resnet18_image = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "torch.onnx.export(model, resnet18_image, \"./resnet18/resnet18.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7369a7e8-156c-448a-aa15-1cebf0a4be0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully TensorRT Engine Configured to Max Batch\n",
      "\n",
      "\n",
      "Successfully Convert ONNX to TensorRT Dynamic Engine\n",
      "Serialized engine saved in engine path: ./resnet18/resnet18.engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "class TensorRTConversion:\n",
    "    \"\"\"\n",
    "    \tpath: to onnx\n",
    "    \tpath: to engine\n",
    "    \tmaxworkspace: gb < lgb\n",
    "    \tprecision: 16 float and half precision\n",
    "    \tInference mode: Dynamic Batch [1, 10, 20]\n",
    "\t\"\"\"\n",
    "    def __init__(self, path_to_onnx, path_to_engine, max_workspace_size=1 << 30, half_precision=False):\n",
    "        self.TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "        self.path_to_onnx = path_to_onnx\n",
    "        self.path_to_engine = path_to_engine\n",
    "        self.max_workspace_size = max_workspace_size\n",
    "        self.half_precision = half_precision\n",
    "    \"\"\"\n",
    "        { INIT BUILD\n",
    "        INIT CONFIG\n",
    "        INIT EXPLICIT BATCH\n",
    "        INIT NETWORK }\n",
    "        Tensorrt >= 8.0.0\n",
    "    \"\"\"\n",
    "    def convert(self):\n",
    "        builder = trt.Builder(self.TRT_LOGGER)\n",
    "        config = builder.create_builder_config()\n",
    "\n",
    "        # config.max_workspace_size = self.max_workspace_size\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30) \n",
    "        \n",
    "        explicit_batch = 1<< int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "        network = builder.create_network(explicit_batch)\n",
    "\n",
    "        parser = trt.OnnxParser(network, self.TRT_LOGGER)\n",
    "\n",
    "        with open(self.path_to_onnx, 'rb') as model_onnx:\n",
    "            if not parser.parse(model_onnx.read()):\n",
    "                print(\"ERROR: Failed to parse ONNX Model\")\n",
    "                for error in parser.errors:\n",
    "                    print(error)\n",
    "                return None\n",
    "\n",
    "        # Set profile for explicit batch\n",
    "        profile = builder.create_optimization_profile()\n",
    "        profile.set_shape(\"input_name\", min=(1, 3, 224, 224), opt=(10, 3, 224, 224), max=(20, 3, 224, 224))\n",
    "        config.add_optimization_profile(profile)\n",
    "        print(\"Successfully TensorRT Engine Configured to Max Batch\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if builder.platform_has_fast_fp16:\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "        engine = builder.build_serialized_network(network, config)\n",
    "\n",
    "        with open(self.path_to_engine, \"wb\") as f_engine:\n",
    "            f_engine.write(engine)\n",
    "\n",
    "        print(\"Successfully Convert ONNX to TensorRT Dynamic Engine\")\n",
    "        print(f\"Serialized engine saved in engine path: {self.path_to_engine}\")\n",
    "\n",
    "# Init class\n",
    "convert = TensorRTConversion(\"./resnet18/resnet18.onnx\", \"./resnet18/resnet18.engine\")\n",
    "# Call class method\n",
    "convert.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f97926-bd3c-4610-af9f-1fcbfe92982c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
