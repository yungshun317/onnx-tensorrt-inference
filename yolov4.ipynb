{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991290c1-bed7-4195-bc25-7805af484b86",
   "metadata": {},
   "source": [
    "# YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd820d09-66db-4767-9926-4279140acf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Python Packages\n",
    "    1. os\n",
    "    2. cv2\n",
    "    3. time\n",
    "'''\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "'''\n",
    "    Class Components\n",
    "    class Name : YoloV4\n",
    "    class Init components : nms_threshold, confidence_threshold, class_labels, image_path, yolov4 : [path_to_cfg_yolo, path_to_weights\n",
    "    target: YOLOV4 Inference on Images\n",
    "'''\n",
    "class YoloV4DNN:\n",
    "\n",
    "    # Initialization of  Parameters\n",
    "    def __init__(self, nms_threshold, conf_threshold, class_labels, image_path, path_to_cfg, path_to_weights):\n",
    "\n",
    "        # non max suppression threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "\n",
    "        # confidence threshold\n",
    "        self.conf_threshold = conf_threshold\n",
    "\n",
    "        # class labels \n",
    "        self.class_labels = class_labels\n",
    "        \n",
    "        # image path\n",
    "        self.image_path = image_path\n",
    "\n",
    "        # path to configuration yolov4\n",
    "        self.path_to_cfg = path_to_cfg\n",
    "\n",
    "        # path to weights yolov4\n",
    "        self.path_to_weights = path_to_weights\n",
    "\n",
    "        # read classes coco file with open()\n",
    "        with open(class_labels, 'r') as read_class:\n",
    "            self.class_labels= [ classes.strip() for classes in read_class.readlines()]\n",
    "\n",
    "\n",
    "        # frame image\n",
    "        # load images \n",
    "        self.frames = self.load_images(self.image_path)\n",
    "\n",
    "\n",
    "        # preprocess images and resize it\n",
    "        for self.frame in self.frames:\n",
    "            \n",
    "            self.image = cv2.imread(self.frame)\n",
    "            \n",
    "            # get height and width of images\n",
    "\n",
    "            self.original_h, self.original_w = self.image.shape[:2]\n",
    "          \n",
    "            dimension = (640, 640)\n",
    "\n",
    "            # resize images\n",
    "            self.resize_image = cv2.resize(self.image, dimension, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # get new height and width of resized image\n",
    "\n",
    "            self.new_h, self.new_w = self.resize_image.shape[:2]\n",
    "\n",
    "            # Call Function Inference RUN\n",
    "\n",
    "            self.inference_run(self.resize_image)\n",
    "    \n",
    "    '''\n",
    "            Function Target: Load Images\n",
    "            param[1] : self\n",
    "            param[2]: image_path\n",
    "\n",
    "    '''\n",
    "    def load_images(self, image_path):\n",
    "\n",
    "            # list of images\n",
    "\n",
    "        img_list = []\n",
    "\n",
    "        for img_original in os.listdir(image_path):\n",
    "            if img_original.endswith('.jpg') or img_original.endswith('.jpeg') or img_original.endswith('.png'):\n",
    "\n",
    "                img_full_path = os.path.join(image_path, img_original)\n",
    "\n",
    "                img_list.append(img_full_path)\n",
    "                \n",
    "        return img_list\n",
    "\n",
    "    '''\n",
    "        target: Inference DNN Opencv with ONNX\n",
    "        param[1]: path to yolov4 confioguration\n",
    "        param[2]:  path to yolov4 weights\n",
    "    '''\n",
    "\n",
    "    def inference_dnn(self, path_to_cfg, path_to_weights):\n",
    "\n",
    "        # read dnn of yolov4\n",
    "        # weights and config\n",
    "        network = cv2.dnn.readNet(path_to_cfg, path_to_weights)\n",
    "        # gpu or cpu \n",
    "        network.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        network.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16) # floating point 16\n",
    "\n",
    "        #creates net from file with trained weights and config, \n",
    "        model = cv2.dnn_DetectionModel(network)\n",
    "\n",
    "        #set model parameters \n",
    "\n",
    "        model.setInputParams(size=(416, 416), scale=1/255, swapRB=True)\n",
    "\n",
    "        '''\n",
    "        classIds\tClass indexes in result detection.\n",
    "        [out]\tconfidences\tA set of corresponding confidences.\n",
    "        [out]\tboxes\tA set of bounding boxes.\n",
    "        '''\n",
    "        classes, scores, boxes = model.detect(self.image, self.conf_threshold, self.nms_threshold)\n",
    "\n",
    "        return classes, scores, boxes\n",
    "    \n",
    "\n",
    "    '''\n",
    "    target: Inference Run and Draw Bounding boxes\n",
    "    param[1] : image\n",
    "\n",
    "    '''\n",
    "\n",
    "    def inference_run(self, image):\n",
    "\n",
    "        # start \n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # get classes, get boxes, get score\n",
    "        # inference for every frame\n",
    "        getClasses, getScores, getBoxes = self.inference_dnn(self.path_to_cfg, self.path_to_weights)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # FRAME time\n",
    "\n",
    "        frame_time = (end-start) * 1000\n",
    "\n",
    "        # Frame per second\n",
    "\n",
    "        FPS = 1.0 * (end-start)\n",
    " \n",
    "        '''\n",
    "        calculate new scale of image which is image formed between original and resized\n",
    "        '''\n",
    "\n",
    "        # new image ratio  height\n",
    "        ratio_h = self.new_h / self.original_h\n",
    "\n",
    "        # new image ratio width\n",
    "        ratio_w = self.new_w / self.original_w\n",
    " \n",
    "        for (class_id, score, box) in zip(getClasses, getScores, getBoxes):\n",
    "            #print(f\"Class ID: {class_id}, Score : {score},  Box: {box}\")\n",
    "\n",
    "            print(f\"Box Coordinates: \", box)\n",
    "            \n",
    "            # normalize bounding box to detection\n",
    "            box[0] = int(box[0] * ratio_w) # x\n",
    "            box[1] = int(box[1] * ratio_h) # y\n",
    "            box[2] = int(box[2] * ratio_w) # width\n",
    "            box[3] = int(box[3] * ratio_h) # height\n",
    "\n",
    "\n",
    "            cv2.rectangle(image, box, (0,255,0),2)\n",
    "            label = \"Frame Time : %.2f ms, FPS : %.2f , ID: %s, Score: %.2f,\" % (frame_time, FPS ,self.class_labels[class_id], score)\n",
    "\n",
    "            # calculate fps\n",
    "           \n",
    "            cv2.putText(image,label, (box[0]-30, box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  (252, 0, 0), 2)\n",
    "        \n",
    "        # show image\n",
    "        cv2.imshow(\"Image Detected :\", image)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "path_to_classes = '/yolov4/coco-classes.txt'\n",
    "image_path = '/yolov4/images'\n",
    "path_to_cfg_yolov4 = '/yolov4/models/yolov4-tiny.cfg'\n",
    "path_to_weights_yolov4 = '/yolov4/models/yolov4-tiny.weights'\n",
    "\n",
    "## call class instance\n",
    "\n",
    "YoloV4(0.3, 0.38, path_to_classes, image_path, path_to_cfg_yolov4, path_to_weights_yolov4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53982905-ebec-40bd-90e7-a6c6ba8c163d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
