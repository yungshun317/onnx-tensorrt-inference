{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991290c1-bed7-4195-bc25-7805af484b86",
   "metadata": {},
   "source": [
    "# YOLOv4\n",
    "## Images\n",
    "1. `cv.dnn.readNet(model, config=\"\", framework=\"\")`: Reads deep learning network represented in one of the supported formats.\n",
    "    - `model`\n",
    "        - `*.caffemodel`: Caffe\n",
    "        - `*.pb`: TensorFlow\n",
    "        - `*.t7`: PyTorch\n",
    "        - `*.weights`: Darknet\n",
    "        - `*.bin`: DLDT\n",
    "        - `*.onnx`: ONNX\n",
    "    - `config`\n",
    "        - `*.prototxt`: Caffe\n",
    "        - `*.pbtxt`: TensorFlow\n",
    "        - `*.cfg`: Darknet\n",
    "        - `*.xml`: DLDT\n",
    "2. `cv.dnn.readNet(framework, bufferModel, bufferConfig=\"\")`: Overloaded member function of the above one.\n",
    "3. `cv.dnn.Model.setInputParams(scale=1.0, size, mean, swapRB=False, crop=False)`: `scale`, `size`, `mean` indicates multiplier for frame values, new input size, and scalar with mean values which are subtracted from channels respectively. The `swapRB` flag means that swap first & last channel, and `crop` denotes whether image will be cropped after resize or not. The formula is `blob(n, c, y, x) = scale * resize(frame(y, x, c)) - mean(c)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd820d09-66db-4767-9926-4279140acf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box Coordinates: [ 664    0  650 1092]\n",
      "Box Coordinates: [139  24 503 481]\n",
      "Box Coordinates: [106  33 802 659]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.YOLOv4 at 0x7963389a1df0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Python Packages\n",
    "    1. os\n",
    "    2. cv2\n",
    "    3. time\n",
    "'''\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "'''\n",
    "    Class Components\n",
    "    class Name: YOLOv4\n",
    "    class Init components : nms_threshold, confidence_threshold, class_labels, image_path, path_to_cfg, path_to\n",
    "    target: YOLOv4 Inference on Images\n",
    "'''\n",
    "class YOLOv4:\n",
    "    # Initialization of  Parameters\n",
    "    def __init__(self, nms_threshold, conf_threshold, path_to_classes, image_path, path_to_cfg, path_to_weights):\n",
    "        # Non max suppression threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "        # Confidence threshold\n",
    "        self.conf_threshold = conf_threshold\n",
    "        # Class labels \n",
    "        self.path_to_classes = path_to_classes\n",
    "        # Image path\n",
    "        self.image_path = image_path\n",
    "        # Path to configuration\n",
    "        self.path_to_cfg = path_to_cfg\n",
    "        # Path to weights\n",
    "        self.path_to_weights = path_to_weights\n",
    "        # Read classes file with `open()`\n",
    "        with open(path_to_classes, 'r') as read_class:\n",
    "            self.class_labels = [classes.strip() for classes in read_class.readlines()]\n",
    "\n",
    "        # Frame image\n",
    "        # Load images \n",
    "        self.frames = self.load_images(self.image_path)\n",
    "\n",
    "        # Preprocess images and resize it\n",
    "        for self.frame in self.frames:\n",
    "            self.image = cv2.imread(self.frame)\n",
    "            \n",
    "            # Get height and width of images\n",
    "            self.original_h, self.original_w = self.image.shape[:2]\n",
    "            dimension = (640, 640)\n",
    "            # Resize images\n",
    "            self.resized_image = cv2.resize(self.image, dimension, interpolation=cv2.INTER_AREA)\n",
    "            # Get new height and width of resized image\n",
    "            self.new_h, self.new_w = self.resized_image.shape[:2]\n",
    "\n",
    "            # Call function `inference_run`\n",
    "            self.inference_run(self.resized_image)\n",
    "            \n",
    "    '''\n",
    "        Function target: Load images from the image path\n",
    "        param[1]: self\n",
    "        param[2]: image_path\n",
    "    '''\n",
    "    def load_images(self, image_path):\n",
    "        # List of images\n",
    "        image_list = []\n",
    "        \n",
    "        for image_original in os.listdir(image_path):\n",
    "            if image_original.endswith('.jpg') or image_original.endswith('.jpeg') or image_original.endswith('.png'):\n",
    "                image_full_path = os.path.join(image_path, image_original)\n",
    "                image_list.append(image_full_path)                \n",
    "        \n",
    "        return image_list\n",
    "\n",
    "    '''\n",
    "        target: Inference DNN Opencv with ONNX\n",
    "        param[1]: path to YOLOv4 confioguration\n",
    "        param[2]: path to YOLOv4 weights\n",
    "    '''\n",
    "    def inference_dnn(self, path_to_cfg, path_to_weights):\n",
    "        # Read YOLOv4's weights and configuration\n",
    "        network = cv2.dnn.readNet(path_to_cfg, path_to_weights)\n",
    "        # GPU or CPU\n",
    "        network.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        # Floating point 16\n",
    "        network.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
    "\n",
    "        # Create net from file with trained weights and config\n",
    "        model = cv2.dnn_DetectionModel(network)\n",
    "        # Set model parameters \n",
    "        model.setInputParams(size=(416, 416), scale=1 / 255, swapRB=True)\n",
    "        '''\n",
    "        classes: Class indexes in result detection\n",
    "        confidences: A set of corresponding confidences\n",
    "        boxes: A set of bounding boxes\n",
    "        '''\n",
    "        classes, scores, boxes = model.detect(self.image, self.conf_threshold, self.nms_threshold)\n",
    "\n",
    "        return classes, scores, boxes\n",
    "    \n",
    "    '''\n",
    "    target: Inference Run and Draw Bounding boxes\n",
    "    param[1]: image\n",
    "    '''\n",
    "    def inference_run(self, image):\n",
    "        # Start \n",
    "        start = time.time()\n",
    "\n",
    "        # Get classes, boxes & score then make inferences for every frame\n",
    "        classes, scores, boxes = self.inference_dnn(self.path_to_cfg, self.path_to_weights)\n",
    "        end = time.time()\n",
    "\n",
    "        # Frame time\n",
    "        frame_time = end - start\n",
    "        # Frame per second\n",
    "        fps = int(1 / frame_time)\n",
    " \n",
    "        '''\n",
    "        Calculate new scale of image which is image formed between original and resized\n",
    "        '''\n",
    "        # New image height ratio\n",
    "        ratio_h = self.new_h / self.original_h\n",
    "        # New image width ratio\n",
    "        ratio_w = self.new_w / self.original_w\n",
    " \n",
    "        for (class_idx, score, box) in zip(classes, scores, boxes):\n",
    "            # print(f\"Class ID: {class_idx}, Score : {score},  Box: {box}\")\n",
    "            print(f\"Box Coordinates:\", box)\n",
    "            \n",
    "            # Normalize bounding box to detection\n",
    "            # x\n",
    "            box[0] = int(box[0] * ratio_w)\n",
    "            # y\n",
    "            box[1] = int(box[1] * ratio_h)\n",
    "            # Width\n",
    "            box[2] = int(box[2] * ratio_w)\n",
    "            # Height\n",
    "            box[3] = int(box[3] * ratio_h)\n",
    "\n",
    "            cv2.rectangle(image, box, (0, 255, 0), 2)\n",
    "            label = \"Frame Time: %.2f ms, FPS: %.2f, ID: %s, Score: %.2f,\" % (frame_time, fps, self.class_labels[class_idx], score)\n",
    "\n",
    "            # Calculate fps\n",
    "            cv2.putText(image, label, (box[0] - 30, box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  (252, 0, 0), 2)\n",
    "        \n",
    "        # Show image\n",
    "        cv2.imshow(\"Image Detected:\", image)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "path_to_classes = 'yolov4/coco-classes.txt'\n",
    "image_path = 'yolov4/images'\n",
    "path_to_cfg = 'yolov4/models/yolov4-tiny.cfg'\n",
    "path_to_weights = 'yolov4/models/yolov4-tiny.weights'\n",
    "\n",
    "# Call class instance\n",
    "YOLOv4(nms_threshold=0.3, conf_threshold=0.38, path_to_classes=path_to_classes, image_path=image_path, path_to_cfg=path_to_cfg, path_to_weights=path_to_weights)\n",
    "# If the log shows `setUpNet DNN module was not built with CUDA backend; switching to CPU`, you need to build OpenCV with CUDA from source in order to use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780860d3-f956-4dfa-9c3a-304868f91995",
   "metadata": {},
   "source": [
    "## Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53982905-ebec-40bd-90e7-a6c6ba8c163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Python Packages\n",
    "    1. os\n",
    "    2. cv2\n",
    "    3. time\n",
    "'''\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "'''\n",
    "    Class Components\n",
    "    class Name : YoloV4DNN\n",
    "    class Init components : nms_threshold, confidence_threshold, class_labels, image_path, yolov4 : [path_to_cfg_yolo, path_to_weights\n",
    "    target: YOLOV4 DNN Inference on Images\n",
    "'''\n",
    "class YOLOv4:\n",
    "    # Initialize of parameters\n",
    "    def __init__(self, nms_threshold, conf_threshold, path_to_classes, video_file, path_to_cfg, path_to_weights):\n",
    "        # Non max suppression threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "        # Confidence threshold\n",
    "        self.conf_threshold = conf_threshold\n",
    "        # Class labels \n",
    "        self.path_to_classes = path_to_classes\n",
    "        # Video path\n",
    "        self.video_file = video_file\n",
    "        # Path to configuration\n",
    "        self.path_to_cfg = path_to_cfg\n",
    "        # Path to weights\n",
    "        self.path_to_weights = path_to_weights\n",
    "\n",
    "        # Read classes COCO file with `open()`\n",
    "        with open(path_to_classes, 'r') as read_class:\n",
    "            self.class_labels= [classes.strip() for classes in read_class.readlines()]\n",
    "\n",
    "    '''\n",
    "        target: Inference DNN Opencv with ONNX\n",
    "        param[1]: path to yolov4 confioguration\n",
    "        param[2]:  path to yolov4 weights\n",
    "    '''\n",
    "    def inference_dnn(self, frame, path_to_cfg, path_to_weights):\n",
    "        # Read YOLOv4's weights and configuration\n",
    "        network = cv2.dnn.readNet(path_to_cfg, path_to_weights)\n",
    "        # GPU or CPU \n",
    "        network.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        # Floating point 16\n",
    "        network.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16) \n",
    "\n",
    "        # Create net from file with trained weights and config \n",
    "        model = cv2.dnn_DetectionModel(network)\n",
    "\n",
    "        # Set model parameters \n",
    "        model.setInputParams(size=(416, 416), scale=1 / 255, swapRB=True)\n",
    "\n",
    "        '''\n",
    "        class_ids: Class indexes in result detection.\n",
    "        [out] confidences: A set of corresponding confidences.\n",
    "        [out] boxes: A set of bounding boxes.\n",
    "        '''\n",
    "        classes, scores, boxes = model.detect(frame, self.conf_threshold, self.nms_threshold)\n",
    "\n",
    "        return classes, scores, boxes\n",
    "    \n",
    "    '''\n",
    "    target: Inference run & draw bounding boxes\n",
    "    param[1]: image\n",
    "    '''\n",
    "    def inference_run(self):\n",
    "        video_capture = cv2.VideoCapture(self.video_file)\n",
    "\n",
    "        if (video_capture.isOpened() == False):\n",
    "            print('Error openeing video File')\n",
    "        \n",
    "        while(video_capture.isOpened()):\n",
    "            # Start\n",
    "            grabbed, frame = video_capture.read()\n",
    "\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            # Resize frame\n",
    "            frame = cv2.resize(frame, (1000, 800)) \n",
    "\n",
    "            # Start\n",
    "            start = time.time()\n",
    "\n",
    "            # Get classes, boxes & scores and make inference for every frame\n",
    "            classes, scores, boxes = self.inference_dnn(frame, self.path_to_cfg, self.path_to_weights)\n",
    "\n",
    "            # End\n",
    "            end = time.time()\n",
    "            \n",
    "            # Frame time\n",
    "            frame_time = end - start\n",
    "            # Frame per second\n",
    "            fps = int(1 / frame_time)\n",
    "    \n",
    "            '''\n",
    "            Calculate new scale of image which is image formed between original and resized\n",
    "            '''                   \n",
    "            for (class_idx, score, box) in zip(classes, scores, boxes):\n",
    "                # print(f\"Class ID: {class_id}, Score : {score},  Box: {box}\")\n",
    "\n",
    "                cv2.rectangle(frame , box, (0, 255, 0), 2)\n",
    "                label = \"Frame Time: %.2f ms, FPS: %.2f, ID: %s, Score: %.2f,\" % (frame_time, fps, self.class_labels[class_idx], score)\n",
    "\n",
    "                # Calculate FPS\n",
    "                cv2.putText(frame, label, (box[0] - 40, box[1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (252, 0, 0), 2)\n",
    "        \n",
    "            # cv2.namedWindow('Image Detected:', cv2.WINDOW_NORMAL)\n",
    "            # cv2.resizeWindow(\"Image Detected: \", 1000, 1000)\n",
    "            cv2.imshow(\"Image detected:\", frame)\n",
    "\n",
    "            # Set `delay` for `cv2.waitKey()`\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                    \n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "def main():\n",
    "    # Paths\n",
    "    path_to_classes = 'yolov4/coco-classes.txt'\n",
    "    video_file = 'yolov4/videos/main_demo.mp4'\n",
    "    path_to_cfg = 'yolov4/models/yolov4-tiny.cfg'\n",
    "    path_to_weights = 'yolov4/models/yolov4-tiny.weights'\n",
    "\n",
    "    # Call class instance\n",
    "    yolo = YOLOv4(nms_threshold=0.3, conf_threshold=0.38, path_to_classes=path_to_classes, video_file=video_file, path_to_cfg=path_to_cfg, path_to_weights=path_to_weights)\n",
    "    yolo.inference_run()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f28d0a-2884-4673-850d-9eaa367a8f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
